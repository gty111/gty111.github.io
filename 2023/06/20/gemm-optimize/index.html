<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Optimize GEMM step by step - TianYu GUO&#039;s homepage</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="TianYu GUO&#039;s homepage"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="TianYu GUO&#039;s homepage"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="一步步优化GEMM系列，每次引入一个优化概念并对比性能变化"><meta property="og:type" content="blog"><meta property="og:title" content="Optimize GEMM step by step"><meta property="og:url" content="https://gty111.github.io/2023/06/20/gemm-optimize/"><meta property="og:site_name" content="TianYu GUO&#039;s homepage"><meta property="og:description" content="一步步优化GEMM系列，每次引入一个优化概念并对比性能变化"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://gty111.github.io/img/gemm_vec.png"><meta property="og:image" content="https://gty111.github.io/img/smem_bank.png"><meta property="og:image" content="https://gty111.github.io/img/async_copy.png"><meta property="og:image" content="https://gty111.github.io/img/mma_dataflow.png"><meta property="og:image" content="https://gty111.github.io/img/prefetch.png"><meta property="og:image" content="https://gty111.github.io/img/gemm_vec1.png"><meta property="og:image" content="https://gty111.github.io/img/smem_bk.png"><meta property="og:image" content="https://gty111.github.io/img/smem_bk1.png"><meta property="og:image" content="https://gty111.github.io/img/coalesce.png"><meta property="og:image" content="https://gty111.github.io/img/ncu_ui.png"><meta property="article:published_time" content="2023-06-20T18:57:25.000Z"><meta property="article:modified_time" content="2024-03-28T01:58:26.750Z"><meta property="article:author" content="TianYu GUO"><meta property="article:tag" content="GEMM"><meta property="article:tag" content="cutlass"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://gty111.github.io/img/gemm_vec.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://gty111.github.io/2023/06/20/gemm-optimize/"},"headline":"Optimize GEMM step by step","image":["https://gty111.github.io/img/gemm_vec.png","https://gty111.github.io/img/smem_bank.png","https://gty111.github.io/img/async_copy.png","https://gty111.github.io/img/mma_dataflow.png","https://gty111.github.io/img/prefetch.png","https://gty111.github.io/img/gemm_vec1.png","https://gty111.github.io/img/smem_bk.png","https://gty111.github.io/img/smem_bk1.png","https://gty111.github.io/img/coalesce.png","https://gty111.github.io/img/ncu_ui.png"],"datePublished":"2023-06-20T18:57:25.000Z","dateModified":"2024-03-28T01:58:26.750Z","author":{"@type":"Person","name":"TianYu GUO"},"publisher":{"@type":"Organization","name":"TianYu GUO's homepage","logo":{"@type":"ImageObject","url":"https://gty111.github.io/img/logo.jpg"}},"description":"一步步优化GEMM系列，每次引入一个优化概念并对比性能变化"}</script><link rel="canonical" href="https://gty111.github.io/2023/06/20/gemm-optimize/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.jpg" alt="TianYu GUO&#039;s homepage" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/info">About Me</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/gty111"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-20T18:57:25.000Z" title="6/20/2023, 6:57:25 PM">2023-06-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-03-28T01:58:26.750Z" title="3/28/2024, 1:58:26 AM">2024-03-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Technology/">Technology</a></span><span class="level-item">24 minutes read (About 3603 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Optimize GEMM step by step</h1><div class="content"><p>一步步优化GEMM系列，每次引入一个优化概念并对比性能变化</p>
<p><img src="/img/gemm_vec.png"></p>
<span id="more"></span>

<blockquote>
<p>点击每个标题链接跳转到对应github仓库</p>
</blockquote>
<h2 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h2><p>首先我们构建了一个初级的GEMM kernel，它使用CUDA <code>mma.sync</code>指令来使用GPU tensor core单元，并对比了和cutlass算子的性能</p>
<p>上图展示了GEMM MMA的计算流程，蓝色部分代表1个block要计算的部分，蓝色部分下的每个小方块代表每个warp的计算部分，右侧青色部分代表每个warp的计算部分，青色部分下的每个小方块代表tensor core支持的分块大小，在调用tensor core之前，加载一个绿色方块和红色方块进入共享内存，之后每个warp独立同步地调用<code>mma.sync</code> 来计算每个分块的结果，其中 <code>M&#39;</code>、<code>N&#39;</code> 、<code>K&#39;</code> 代表tensor core单元支持计算的GEMM维度。</p>
<p>baseline性能: 3.44% (相比cutlass)</p>
<h2 id="使用向量化-vector"><a href="#使用向量化-vector" class="headerlink" title="使用向量化(vector)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/vector">使用向量化(vector)</a></h2><p>vector分支主要介绍向量化load&#x2F;store，</p>
<p>优化后性能: 4.74%</p>
<p>向量化在不同层级的表现</p>
<h3 id="cu-level"><a href="#cu-level" class="headerlink" title="cu level"></a>cu level</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*reinterpret_cast&lt;float4*&gt;(&amp;A[tileIdx]) = *reinterpret_cast&lt;float4*&gt;(&amp;arg.A[rowA_0*arg.problem_size.k()+colA_0]);</span><br></pre></td></tr></table></figure>

<h3 id="ptx-level"><a href="#ptx-level" class="headerlink" title="ptx level"></a>ptx level</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ld.global.v4.u32 &#123;%r161, %r162, %r163, %r164&#125;, [%rd5];</span><br><span class="line">st.shared.v4.u32 [%r16], &#123;%r161, %r162, %r163, %r164&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="SASS-level"><a href="#SASS-level" class="headerlink" title="SASS level"></a>SASS level</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LDG.E.128 R8, [R10.64] ;</span><br><span class="line">STS.128 [R17], R8 ;</span><br></pre></td></tr></table></figure>

<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 15.816908(ms) Gflops: 69514.954246</span><br><span class="line">[            MMA_base] Runtime: 460.150970(ms) Gflops: 2389.458457</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[             MMA_vec] Runtime: 333.618652(ms) Gflops: 3295.713894</span><br><span class="line">[        MMA_vec==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="避免bank冲突并且合并访存-bfco"><a href="#避免bank冲突并且合并访存-bfco" class="headerlink" title="避免bank冲突并且合并访存(bfco)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/bfco">避免bank冲突并且合并访存(bfco)</a></h2><p>bfco分支主要介绍如何通过解决shared memory bank conflict 和 memory coalesce (访存合并) 来优化性能</p>
<p>优化后性能: 5.00%</p>
<h3 id="Shared-memory-bank"><a href="#Shared-memory-bank" class="headerlink" title="Shared memory bank"></a>Shared memory bank</h3><p><a target="_blank" rel="noopener" href="https://docs.nvidia.cn/cuda/cuda-c-programming-guide/index.html#shared-memory-5-x">参考cuda programming guide</a></p>
<p><img src="/img/smem_bank.png"></p>
<p>要注意连续的bank存储连续的字(32-bits)，这里字的大小为32 bits，总共有32个bank</p>
<p>要想解决bank conflict问题，要将一个warp内线程读取的shared memory尽量分散到不同的bank里</p>
<h3 id="memory-coalesce（访存合并）"><a href="#memory-coalesce（访存合并）" class="headerlink" title="memory coalesce（访存合并）"></a>memory coalesce（访存合并）</h3><p>访存合并用一句话来简单概括就是一个warp内线程读取的global memory尽量是连续的且128字节对齐</p>
<p>为什么是128字节对齐而不是其他数字？我的理解是cache line的大小是128字节，这样一个warp内的访存可以合并成以cache line为基本单位的memory transaction</p>
<h3 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h3><p>为了解决bank conflict 和 memory coalesce，对代码做的主要修改为变量 <code>tileidx</code></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// in function loadtileC</span></span><br><span class="line"><span class="type">int</span> tileIdx = threadIdx.x*<span class="number">64</span> + i*<span class="number">4</span>; <span class="comment">// base</span></span><br><span class="line"><span class="type">int</span> tileIdx = threadIdx.x*<span class="number">64</span> + (i+threadIdx.x/<span class="number">1</span>)%<span class="number">16</span>*<span class="number">4</span>; <span class="comment">// bank free</span></span><br><span class="line"><span class="type">int</span> tileIdx = threadIdx.x*<span class="number">4</span> + i*blockDim.x*<span class="number">4</span>; <span class="comment">// memory coalesce + bank free</span></span><br></pre></td></tr></table></figure>

<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 15.788442(ms) Gflops: 69640.288231</span><br><span class="line">[            MMA_base] Runtime: 333.625763(ms) Gflops: 3295.643652</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[              MMA_bf] Runtime: 326.514526(ms) Gflops: 3367.420249</span><br><span class="line">[         MMA_bf==ref] PASS</span><br><span class="line">[           MMA_bf_co] Runtime: 315.669495(ms) Gflops: 3483.110172</span><br><span class="line">[      MMA_bf_co==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="使用异步拷贝-ldgsts"><a href="#使用异步拷贝-ldgsts" class="headerlink" title="使用异步拷贝(ldgsts)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/ldgsts">使用异步拷贝(ldgsts)</a></h2><p>ldgsts 分支主要来介绍使用Ampere引入的异步拷贝来优化性能</p>
<p>优化后性能: 5.36%</p>
<h3 id="异步拷贝"><a href="#异步拷贝" class="headerlink" title="异步拷贝"></a>异步拷贝</h3><p><img src="/img/async_copy.png"></p>
<p>CUDA 11 引入了一个新的async copy(异步拷贝)API来利用 A100 GPU 硬件加速将数据从global memory(全局内存) 直接拷贝到shared memory(共享内存)。异步拷贝会执行从全局内存到共享内存的异步(非阻塞)直接内存传输(旁路SM，也就是不经过寄存器)，它将”从全局内存加载数据到寄存器”和”将数据从寄存器写入共享内存”这两个操作结合成单个且高效的操作。</p>
<p>异步拷贝消除了通过寄存器存储中间数据的需要，进而减少了所需的寄存器访问带宽。它有效地利用了存储带宽并且降低了功耗。正如它的名字所表明，异步拷贝是异步完成的，允许其他的计算和从全局内存到共享内存的数据搬运同时发生。异步拷贝通过新的同步特性来通知程序数据搬运的完成。</p>
<p>旁路L1和寄存器可以明显地提升数据拷贝的性能，特别是对于多个连续的异步拷贝操作，这些操作将大量数据从全局内存复制到共享内存。</p>
<p>异步拷贝指令有两个变种，适用于不同的使用场景。BYPASS：旁路掉L1缓存和寄存器，ACCESS：将数据保存到L1以供后续访问和重用。</p>
<h3 id="cu-level-1"><a href="#cu-level-1" class="headerlink" title="cu level"></a>cu level</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">asm volatile(&quot;cp.async.cg.shared.global [%0], [%1], %2;\n&quot;</span><br><span class="line">                :: &quot;r&quot;((uint32_t)__cvta_generic_to_shared(&amp;C[tileIdx])),</span><br><span class="line">                &quot;l&quot;(&amp;arg.C[rowC_0*arg.problem_size.n()+colC_0]),</span><br><span class="line">                &quot;n&quot;(16)</span><br><span class="line">            );</span><br></pre></td></tr></table></figure>

<h3 id="ptx-level-1"><a href="#ptx-level-1" class="headerlink" title="ptx level"></a>ptx level</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp.async.cg.shared.global [%r158], [%rd18], 16;</span><br></pre></td></tr></table></figure>

<h3 id="SASS-level-1"><a href="#SASS-level-1" class="headerlink" title="SASS level"></a>SASS level</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LDGSTS.E.BYPASS.128 [R7+0x1800], [R4.64] ;</span><br></pre></td></tr></table></figure>


<h3 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 15.938765(ms) Gflops: 68983.491336</span><br><span class="line">[            MMA_base] Runtime: 315.683228(ms) Gflops: 3482.958649</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[            MMA_ldgsts] Runtime: 297.315948(ms) Gflops: 3698.125289</span><br><span class="line">[       MMA_ldgsts==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="使用寄存器-reg"><a href="#使用寄存器-reg" class="headerlink" title="使用寄存器(reg)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/reg">使用寄存器(reg)</a></h2><p>reg 分支介绍使用寄存器来优化性能</p>
<p>优化后性能: 35.39%</p>
<h3 id="CUDA中的寄存器"><a href="#CUDA中的寄存器" class="headerlink" title="CUDA中的寄存器"></a>CUDA中的寄存器</h3><p>寄存器的概念可能对于高级编程者来说是比较陌生的，因为在编程中一般并不会刻意地声明要使用寄存器来做什么操作，编译器会帮我们处理好这个问题，这就导致了在编写CUDA算子时往往会忽略掉寄存器的使用，可以通过ncu或编译时设置编译参数来查看kernel中每个线程使用了几个寄存器，比如在我们对比的cutlass的kernel中每个线程使用了230个寄存器，但是本例中baseline的kernel中每个线程只使用了32个寄存器，所以可以考虑将频繁使用的<code>tileC</code>(也就是图中的蓝色部分)从共享内存转移到寄存器中。</p>
<p>如何使用寄存器？其实很简单，在kernel中声明变量或数组就可以(不过如果一个线程使用太多寄存器会发生register spilling，可以在编译好程序后反汇编查看下有没有local memory)</p>
<p>在代码中添加了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ElementOutput C_fragment[64];</span><br></pre></td></tr></table></figure>
<p>并修改好相关逻辑后，再次编译发现每个线程使用了156个线程</p>
<h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><p>之前方法优化效果不明显的原因应该是kernel性能瓶颈在别的地方，可以从这个寄存器优化后的版本尝试如果不采用向量化，不解决bank冲突或访存不合并，或者不采用异步拷贝，kernel的性能变化是怎样的？</p>
<h3 id="结果-3"><a href="#结果-3" class="headerlink" title="结果"></a>结果</h3><p>原来没有使用寄存器才是kernel性能差的主要原因…</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 16.149094(ms) Gflops: 68085.036418</span><br><span class="line">[            MMA_base] Runtime: 297.333862(ms) Gflops: 3697.902483</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[            MMA_tune] Runtime: 45.636402(ms) Gflops: 24092.863952</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="使用数据预取-prefetch"><a href="#使用数据预取-prefetch" class="headerlink" title="使用数据预取(prefetch)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/prefetch">使用数据预取(prefetch)</a></h2><p>prefetch 分支介绍使用数据预取来优化性能</p>
<p>优化后性能：39.36%</p>
<p>数据预取需要将缓冲区加倍，主要流程如下</p>
<p>假设计算<code>mma_&#123;i&#125;</code>依赖于数据<code>data_&#123;i&#125;</code>, <code>load data_&#123;i&#125;</code>代表开始加载数据<code>data_&#123;i&#125;</code>, 只有在<code>synchronize</code>后加载的数据才保证可见, 那么数据预取的伪代码如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">load data_&#123;1&#125;</span><br><span class="line"></span><br><span class="line">for i=1:...</span><br><span class="line">    synchronize</span><br><span class="line">    mma_&#123;i&#125;</span><br><span class="line">    load data_&#123;i+1&#125;</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>这样可以让数据加载(data_{i+1})和计算(mma_{i})尽可能重叠起来</p>
<h3 id="结果-4"><a href="#结果-4" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 15.947670(ms) Gflops: 68944.969952</span><br><span class="line">[            MMA_base] Runtime: 45.381512(ms) Gflops: 24228.184273</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[            MMA_tune] Runtime: 40.519497(ms) Gflops: 27135.372140</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure>


<h2 id="关于PTXAS有趣的发现-ptxas"><a href="#关于PTXAS有趣的发现-ptxas" class="headerlink" title="关于PTXAS有趣的发现(ptxas)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/ptxas">关于PTXAS有趣的发现(ptxas)</a></h2><p>ptxas 分支分享一个调优过程中发现的关于ptxas(ptx汇编器)有意思的东西</p>
<h3 id="事情起因"><a href="#事情起因" class="headerlink" title="事情起因"></a>事情起因</h3><p>在优化kernel过程中，发现每个warp循环计算每个Ctile时，都需要从共享内存加载Atile和Btile一次，这样Atile和Btile会被重复加载4次，那其实这里数据是可以复用的，而不用多次加载，于是重新设计了下每个warp计算流程，将4x4tile划分为4个2x2的大tile，每次计算大tile前先把对应的Atile和Btile从共享内存加载到寄存器中，在计算下一个大tile时只需要重新加载一个 A&#x2F;B tile即可(例如从左上角移动到右上角只需要重新加载Btile即可，Atile是可以复用的)，下图为优化前后的计算流程图，其中C tile为每个warp需要计算的矩阵C的部分，图上的数字代表数据块被加载的次数</p>
<p><img src="/img/mma_dataflow.png"></p>
<p>然而就在我把代码写好，验证通过后，惊讶地发现两个kernel的运行时间很接近，通过ncu profile后发现运行的指令数竟然是一样的，反汇编后发现两个kernel的sass指令数竟然是相同的，然后仔细看了下，代码逻辑完全是一模一样的，只是部分寄存器命名不一样，这有点离谱，然后看了下两个kernel的ptx指令逻辑还是不一样的，难道CUDA的ptxas优化的这么离谱。</p>
<p>这里给出kernel的ptx和sass指令</p>
<p>两个kernel的ptx版本分别为 <a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/blob/ptxas/ptx/ptx_mma">ptx_mma</a> 和 <a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/blob/ptxas/ptx/ptx_mma_tune">ptx_mma_tune</a></p>
<p>两个kernel的sass版本分别为 <a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/blob/ptxas/sass/sass_mma">sass_mma</a> 和 <a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/blob/ptxas/sass/sass_mma_tune">sass_mma_tune</a></p>
<h3 id="杂项-1"><a href="#杂项-1" class="headerlink" title="杂项"></a>杂项</h3><p>优化了半天最后发现机器码都是一样的，确实感觉到了编译器的强大，关键是怎么知道代码哪些是已经被编译器优化好了呢。</p>
<p>另外意外发现了A100 80GB 相比A100 40GB 可以提升33%左右的性能，于是感觉很奇怪，这两个版本不就是显存大小不一样嘛，怎么运行速度差距这么大，于是发现A100 80GB显存带宽 2TB&#x2F;s，而40BG版本显存带宽 1.5TB&#x2F;s，这相当于显存带宽提升了33%，这难道全部转化成性能提升了吗？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">A100 40GB</span><br><span class="line">[        problem size] (5120,4096,4096)</span><br><span class="line">[          cutlassMMA] Runtime: 2.370118(ms) Gflops: 72485.278929</span><br><span class="line">[            MMA_base] Runtime: 6.451385(ms) Gflops: 26629.735875</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[            MMA_tune] Runtime: 6.456460(ms) Gflops: 26608.804078</span><br><span class="line">[       MMA_tune==ref] PASS</span><br><span class="line"></span><br><span class="line">A100 80GB</span><br><span class="line">[        problem size] (5120,4096,4096)</span><br><span class="line">[          cutlassMMA] Runtime: 1.781453(ms) Gflops: 96437.410102</span><br><span class="line">[            MMA_base] Runtime: 4.881101(ms) Gflops: 35196.711561</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[            MMA_tune] Runtime: 4.883047(ms) Gflops: 35182.685107</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="优化数据预取-prefetchx"><a href="#优化数据预取-prefetchx" class="headerlink" title="优化数据预取(prefetchx)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/prefetchx">优化数据预取(prefetchx)</a></h2><p>prefetchx 分支和之前的prefetch分支类似，区别是增加了预取数据大小并利用了同步指令<code>cp.async.waitgroup N</code></p>
<p>优化后性能：46.89%</p>
<p>数据预取在之前介绍过，本次优化主要将预取数据的大小增加了1倍，并且显式地调用同步指令<code>cp.async.waitgroup N</code>来确保数据已经拷贝完成，主要流程如下图片</p>
<p><img src="/img/prefetch.png"></p>
<h3 id="结果-5"><a href="#结果-5" class="headerlink" title="结果"></a>结果</h3><blockquote>
<p>PS: 这次测试结果使用的是A100 80GB版本</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 12.857344(ms) Gflops: 85516.235366</span><br><span class="line">[            MMA_base] Runtime: 30.978357(ms) Gflops: 35492.896431</span><br><span class="line">[       MMA_base==ref] PASS</span><br><span class="line">[            MMA_tune] Runtime: 27.419851(ms) Gflops: 40099.109788</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="调整线程块和warp计算的矩阵大小-shape"><a href="#调整线程块和warp计算的矩阵大小-shape" class="headerlink" title="调整线程块和warp计算的矩阵大小(shape)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/shape">调整线程块和warp计算的矩阵大小(shape)</a></h2><p><img src="/img/gemm_vec1.png"></p>
<p>shape 分支调整了每个block和warp计算的矩阵C的大小</p>
<p>优化后性能：62.39%</p>
<p>cutlass 中 <code>ShapeMMAThreadBlock</code> 代表每个线程块计算的矩阵C的大小，而 <code>ShapeMMAWarp</code> 代表每个warp计算的矩阵C的大小</p>
<p>之前手写的 MMA kernel 每个线程块计算 128x64，每个warp计算 64x32，调整后每个线程块计算 128x128，每个warp计算 64x64，这样可以增加数据复用</p>
<p>PS: 实测如果在kernel中申请长度为128的数组，编译器会将其分配到local memory， 所以为了避免这样的情况发生，需要将长度为128的数组分成两个长度为64的数组</p>
<h3 id="结果-6"><a href="#结果-6" class="headerlink" title="结果"></a>结果</h3><blockquote>
<p>PS: 这次测试结果没有对比之前的kernel</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 12.744192(ms) Gflops: 86275.506296</span><br><span class="line">[            MMA_tune] Runtime: 20.427467(ms) Gflops: 53825.156547</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="调整线程块分配到的计算位置-swizzle"><a href="#调整线程块分配到的计算位置-swizzle" class="headerlink" title="调整线程块分配到的计算位置(swizzle)"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/swizzle">调整线程块分配到的计算位置(swizzle)</a></h2><p>swizzle 分支调整每个thread block分配到的计算位置来优化性能</p>
<p>优化后性能: 68.43%</p>
<h3 id="swizzle"><a href="#swizzle" class="headerlink" title="swizzle"></a>swizzle</h3><p>本次优化思路来自于 cutlass 中 <code>ThreadBlockSwizzle</code>，一开始接触可能比较难以理解这个概念，这个swizzle最核心的就是对于 <code>blockIdx</code> 进行如下变换</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x ==&gt; block_idx_x &gt;&gt; log_tile</span><br><span class="line">blockIdx.y ==&gt; (block_idx_y &lt;&lt; log_tile) + ((block_idx_x) &amp; ((1 &lt;&lt; (log_tile)) - 1))</span><br><span class="line">blockIdx.z ==&gt; blockIdx.z</span><br></pre></td></tr></table></figure>

<p>看了上面的变换公式，你可能还是一头雾水，其实我们来用一张图来简单说明(log_tile&#x3D;2), 假如我们启动了一个kernel，它的gridDim为(16,1,1)(即下图中左边的分布)，那么经过 <code>swizzle</code> 变换后得到下图中右边的分布，所以我们可以发现 swizzle 后的线程块在2D分布上满足局部性原理，那这样有什么好处呢，好处就是可以尽量提升L2缓存的命中率或L2缓存中的数据复用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  |  0  4  8  12</span><br><span class="line">                                       |  1  5  9  13 </span><br><span class="line">                                       |  2  6 10  14</span><br><span class="line">                                       |  3  7 11  15</span><br></pre></td></tr></table></figure>

<h3 id="结果-7"><a href="#结果-7" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 12.671488(ms) Gflops: 86770.523274</span><br><span class="line">[            MMA_tune] Runtime: 18.476339(ms) Gflops: 59509.170487</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure>

<h2 id="使用ldmatrix指令"><a href="#使用ldmatrix指令" class="headerlink" title="使用ldmatrix指令"></a><a target="_blank" rel="noopener" href="https://github.com/gty111/GEMM_MMA/tree/ldmatrix">使用ldmatrix指令</a></h2><p><code>ldmatrix.sync</code> 指令是 Warp-level matrix load instruction，它是 <code>mma.sync</code> 对应的load共享内存的指令</p>
<p>优化后性能: 73.65%</p>
<h3 id="解决shared-memory-bank冲突"><a href="#解决shared-memory-bank冲突" class="headerlink" title="解决shared memory bank冲突"></a>解决shared memory bank冲突</h3><p>之前没有注意到shared memory 存在 bank 冲突 ，所以通过调整 shared memory 布局来解决 bank 冲突问题</p>
<p><img src="/img/smem_bk.png"></p>
<p>上图中 0,1,2,3 分别代表每个 warp 一次加载的 shared memory 部分, 加载的部分为 A 矩阵(行主序)</p>
<h3 id="访存合并"><a href="#访存合并" class="headerlink" title="访存合并"></a>访存合并</h3><p>在解决 shared memory bank 冲突时，如果做如下调整会导致 global memory 访存无法合并</p>
<p><img src="/img/smem_bk1.png"></p>
<p>因为 <code>N&#39;=8</code> ， 所以一行正好是 32bytes，即一个sector，而如果一个sector被拆开放到 shared memory 中去会导致访存无法合并，而下图中的变换是可以合并访存的</p>
<p><img src="/img/coalesce.png"></p>
<h3 id="Nsight-Compute"><a href="#Nsight-Compute" class="headerlink" title="Nsight Compute"></a>Nsight Compute</h3><p>Nsight Compute(ncu) 是 NVIDIA 推出的对 kernel profile 工具，之前一直用的命令行方式，最近发现 ncu-ui 输出的信息更完善丰富，比如下图可以对访存进行细致的展示</p>
<p><img src="/img/ncu_ui.png"></p>
<h3 id="结果-8"><a href="#结果-8" class="headerlink" title="结果"></a>结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[        problem size] (8192,8192,8192)</span><br><span class="line">[          cutlassMMA] Runtime: 12.476519(ms) Gflops: 88126.476648</span><br><span class="line">[            MMA_tune] Runtime: 16.939159(ms) Gflops: 64909.456381</span><br><span class="line">[       MMA_tune==ref] PASS</span><br></pre></td></tr></table></figure></div><div class="article-licensing box"><div class="licensing-title"><p>Optimize GEMM step by step</p><p><a href="https://gty111.github.io/2023/06/20/gemm-optimize/">https://gty111.github.io/2023/06/20/gemm-optimize/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>TianYu GUO</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-06-20</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-03-28</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/GEMM/">GEMM</a><a class="link-muted mr-2" rel="tag" href="/tags/cutlass/">cutlass</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/12/04/Tips-for-Linux/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Miscellaneous tips</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/05/14/learn-cutlass-5/"><span class="level-item">learn-cutlass-5</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://gty111.github.io/2023/06/20/gemm-optimize/';
            this.page.identifier = '2023/06/20/gemm-optimize/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'gty111' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-14T11:28:23.000Z">2023-12-14</time></p><p class="title"><a href="/2023/12/14/ebooks/">ebooks and tutorials</a></p><p class="categories"><a href="/categories/Technology/">Technology</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-04T19:05:56.000Z">2023-12-04</time></p><p class="title"><a href="/2023/12/04/Tips-for-Linux/">Miscellaneous tips</a></p><p class="categories"><a href="/categories/Technology/">Technology</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-20T18:57:25.000Z">2023-06-20</time></p><p class="title"><a href="/2023/06/20/gemm-optimize/">Optimize GEMM step by step</a></p><p class="categories"><a href="/categories/Technology/">Technology</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-14T11:48:32.000Z">2023-05-14</time></p><p class="title"><a href="/2023/05/14/learn-cutlass-5/">learn-cutlass-5</a></p><p class="categories"><a href="/categories/Technology/">Technology</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-22T09:33:58.000Z">2023-04-22</time></p><p class="title"><a href="/2023/04/22/NVVM-IR/">NVVM (NVCC &amp; LLVM)</a></p><p class="categories"><a href="/categories/Technology/">Technology</a></p></div></article></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#总体思路"><span class="level-left"><span class="level-item">1</span><span class="level-item">总体思路</span></span></a></li><li><a class="level is-mobile" href="#使用向量化-vector"><span class="level-left"><span class="level-item">2</span><span class="level-item">使用向量化(vector)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#cu-level"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">cu level</span></span></a></li><li><a class="level is-mobile" href="#ptx-level"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">ptx level</span></span></a></li><li><a class="level is-mobile" href="#SASS-level"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">SASS level</span></span></a></li><li><a class="level is-mobile" href="#结果"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#避免bank冲突并且合并访存-bfco"><span class="level-left"><span class="level-item">3</span><span class="level-item">避免bank冲突并且合并访存(bfco)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Shared-memory-bank"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Shared memory bank</span></span></a></li><li><a class="level is-mobile" href="#memory-coalesce（访存合并）"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">memory coalesce（访存合并）</span></span></a></li><li><a class="level is-mobile" href="#代码分析"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">代码分析</span></span></a></li><li><a class="level is-mobile" href="#结果-1"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#使用异步拷贝-ldgsts"><span class="level-left"><span class="level-item">4</span><span class="level-item">使用异步拷贝(ldgsts)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#异步拷贝"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">异步拷贝</span></span></a></li><li><a class="level is-mobile" href="#cu-level-1"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">cu level</span></span></a></li><li><a class="level is-mobile" href="#ptx-level-1"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">ptx level</span></span></a></li><li><a class="level is-mobile" href="#SASS-level-1"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">SASS level</span></span></a></li><li><a class="level is-mobile" href="#结果-2"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#使用寄存器-reg"><span class="level-left"><span class="level-item">5</span><span class="level-item">使用寄存器(reg)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#CUDA中的寄存器"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">CUDA中的寄存器</span></span></a></li><li><a class="level is-mobile" href="#杂项"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">杂项</span></span></a></li><li><a class="level is-mobile" href="#结果-3"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#使用数据预取-prefetch"><span class="level-left"><span class="level-item">6</span><span class="level-item">使用数据预取(prefetch)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#结果-4"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#关于PTXAS有趣的发现-ptxas"><span class="level-left"><span class="level-item">7</span><span class="level-item">关于PTXAS有趣的发现(ptxas)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#事情起因"><span class="level-left"><span class="level-item">7.1</span><span class="level-item">事情起因</span></span></a></li><li><a class="level is-mobile" href="#杂项-1"><span class="level-left"><span class="level-item">7.2</span><span class="level-item">杂项</span></span></a></li></ul></li><li><a class="level is-mobile" href="#优化数据预取-prefetchx"><span class="level-left"><span class="level-item">8</span><span class="level-item">优化数据预取(prefetchx)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#结果-5"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#调整线程块和warp计算的矩阵大小-shape"><span class="level-left"><span class="level-item">9</span><span class="level-item">调整线程块和warp计算的矩阵大小(shape)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#结果-6"><span class="level-left"><span class="level-item">9.1</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#调整线程块分配到的计算位置-swizzle"><span class="level-left"><span class="level-item">10</span><span class="level-item">调整线程块分配到的计算位置(swizzle)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#swizzle"><span class="level-left"><span class="level-item">10.1</span><span class="level-item">swizzle</span></span></a></li><li><a class="level is-mobile" href="#结果-7"><span class="level-left"><span class="level-item">10.2</span><span class="level-item">结果</span></span></a></li></ul></li><li><a class="level is-mobile" href="#使用ldmatrix指令"><span class="level-left"><span class="level-item">11</span><span class="level-item">使用ldmatrix指令</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#解决shared-memory-bank冲突"><span class="level-left"><span class="level-item">11.1</span><span class="level-item">解决shared memory bank冲突</span></span></a></li><li><a class="level is-mobile" href="#访存合并"><span class="level-left"><span class="level-item">11.2</span><span class="level-item">访存合并</span></span></a></li><li><a class="level is-mobile" href="#Nsight-Compute"><span class="level-left"><span class="level-item">11.3</span><span class="level-item">Nsight Compute</span></span></a></li><li><a class="level is-mobile" href="#结果-8"><span class="level-left"><span class="level-item">11.4</span><span class="level-item">结果</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Technology/"><span class="level-start"><span class="level-item">Technology</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/essay/"><span class="level-start"><span class="level-item">essay</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/log/"><span class="level-start"><span class="level-item">log</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/GEMM/"><span class="tag">GEMM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPU/"><span class="tag">GPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IR/"><span class="tag">IR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NVIDIA/"><span class="tag">NVIDIA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cutlass/"><span class="tag">cutlass</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ebook/"><span class="tag">ebook</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tips/"><span class="tag">tips</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tutorial/"><span class="tag">tutorial</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%80%E7%94%9F%E4%B8%80%E8%8A%AF/"><span class="tag">一生一芯</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%B0%E9%9B%B9/"><span class="tag">冰雹</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.jpg" alt="TianYu GUO&#039;s homepage" height="28"></a><p class="is-size-7"><span>&copy; 2024 TianYu GUO</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>