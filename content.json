{"posts":[{"title":"How to build this web","text":"This web is building by Hexo and Icarus. Install Node.js for linux reference this for windows through nvs or nvm for mac through Homebrew or MacPorts Install Hexo (require Node.js)1npm install -g hexo-cli Create your site123456hexo init &lt;folder&gt; cd &lt;folder&gt;npm installnpm install -S hexo-theme-icarus hexo-renderer-inferno # install icarushexo config theme icarus # use theme icarushexo server # start server at localhost Tips about Hexo or Icarus Add read more to your blogs : just add &lt;!-- more --&gt; in your md at proper position. Reference hexo-tutorial getting-started-with-icarus","link":"/2023/03/23/build_web/"},{"title":"learn-cutlass-0","text":"learn cutlass is a series of tutorials to learn cutlass by reading its examples or source code CUTLASS is a header-only template library. After reading that, you will be lost in templates. 00_basic_gemm12345678910111213141516171819// Defines cutlass::gemm::device::Gemm, the generic Gemm computation template class.#include &quot;cutlass/gemm/device/gemm.h&quot;using CutlassGemm = cutlass::gemm::device::Gemm&lt;A_TYPE,A_LAYOUT,B_TYPE,B_LAYOUT,C_TYPE,C_LAYOUT&gt; ;// where A_TYPE is Data-type of A matrix and A_LAYOUT is Layout of A matrixCutlassGemm gemm_operator;CutlassGemm::Arguments args({M , N, K}, {A_POINTER, lda}, {B_POINTER, ldb}, {C_POINTER, ldc}, {C_POINTER, ldc}, {alpha, beta});// where A_POINTER is pointer of A matrix and lda is the number of elements between consecutive rows or colmnscutlass::Status status = gemm_operator(args);// call gemm operation 01_cutlass_utilities1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495// CUTLASS includes needed for half-precision GEMM kernel#include &quot;cutlass/cutlass.h&quot;#include &quot;cutlass/core_io.h&quot;#include &quot;cutlass/layout/matrix.h&quot;#include &quot;cutlass/gemm/device/gemm.h&quot;//// CUTLASS utility includes//// Defines operator&lt;&lt;() to write TensorView objects to std::ostream#include &quot;cutlass/util/tensor_view_io.h&quot;// Defines cutlass::HostTensor&lt;&gt;#include &quot;cutlass/util/host_tensor.h&quot;// Defines cutlass::half_t#include &quot;cutlass/numeric_types.h&quot;// Defines device_memory::copy_device_to_device()#include &quot;cutlass/util/device_memory.h&quot;// Defines cutlass::reference::device::TensorFillRandomGaussian()#include &quot;cutlass/util/reference/device/tensor_fill.h&quot;// Defines cutlass::reference::host::TensorEquals()#include &quot;cutlass/util/reference/host/tensor_compare.h&quot;// Defines cutlass::reference::host::Gemm()#include &quot;cutlass/util/reference/host/gemm.h&quot;// another way to call gemm without using Argumentscutlass::Status status = gemm_op({ {M, N, K}, {A, lda}, {B, ldb}, {C, ldc}, {C, ldc}, {alpha, beta} });// define a tensor (M,N) in cutlass, where DTYPE is data typecutlass::HostTensor&lt;DTYPE,LAYOUT&gt; VAR(cutlass::MatrixCoord(M,N)) ;cutlass::HostTensor&lt;cutlass::half_t, cutlass::layout::ColumnMajor&gt; A(cutlass::MatrixCoord(M, K));// fill a tensor (RandomGaussian) where A.device_view() return TensorView of that tensor in cutlasscutlass::reference::device::TensorFillRandomGaussian( A.device_view(), seed, mean, stddev, bits_less_than_one );// copy data from device to device in cutlass where A.device_data() return pointer of that tensor// A.capacity() return the logical capacity based on extent and layout. May differ from size().cutlass::device_memory::copy_device_to_device( C_reference.device_data(), C_cutlass.device_data(), C_cutlass.capacity());// Copies data from device to hostA.sync_host();// Copies data from host to deviceA.sync_device();// Compute the reference result using the host-side GEMM reference implementation.// I think the only difference between TensorView and TensorRef is that TensorView is read-only // while TensorRef can return pointer of matrixcutlass::reference::host::Gemm&lt; cutlass::half_t, // ElementA cutlass::layout::ColumnMajor, // LayoutA cutlass::half_t, // ElementB cutlass::layout::ColumnMajor, // LayoutB cutlass::half_t, // ElementOutput cutlass::layout::ColumnMajor, // LayoutOutput cutlass::half_t, // ScalarType cutlass::half_t // ComputeType&gt; gemm_ref;gemm_ref( {M, N, K}, // problem size (type: cutlass::gemm::GemmCoord) alpha, // alpha (type: cutlass::half_t) A.host_ref(), // A (type: TensorRef&lt;half_t, ColumnMajor&gt;) B.host_ref(), // B (type: TensorRef&lt;half_t, ColumnMajor&gt;) beta, // beta (type: cutlass::half_t) C_reference.host_ref() // C (type: TensorRef&lt;half_t, ColumnMajor&gt;));// Compare reference to computed resultscutlass::reference::host::TensorEquals( C_reference.host_view(), C_cutlass.host_view()); 04_tile_iterator12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// CUTLASS includes#include &quot;cutlass/transform/threadblock/predicated_tile_iterator.h&quot;#include &quot;cutlass/layout/pitch_linear.h&quot;#include &quot;cutlass/transform/pitch_linear_thread_map.h&quot;//// CUTLASS utility includes//// Defines operator&lt;&lt;() to write TensorView objects to std::ostream#include &quot;cutlass/util/tensor_view_io.h&quot;// Defines cutlass::HostTensor&lt;&gt;#include &quot;cutlass/util/host_tensor.h&quot;// Defines cutlass::reference::host::TensorFill() and// cutlass::reference::host::TensorFillBlockSequential()#include &quot;cutlass/util/reference/host/tensor_fill.h&quot;// For this example, we chose a &lt;64, 4&gt; tile shape. The PredicateTileIterator expects// PitchLinearShape and PitchLinear layout.using Shape = cutlass::layout::PitchLinearShape&lt;64, 4&gt;;using Layout = cutlass::layout::PitchLinear;using Element = int;int const kThreads = 32;// ThreadMaps define how threads are mapped to a given tile. The PitchLinearStripminedThreadMap// stripmines a pitch-linear tile among a given number of threads, first along the contiguous// dimension then along the strided dimension.using ThreadMap = cutlass::transform::PitchLinearStripminedThreadMap&lt;Shape, kThreads&gt;;// Define the PredicateTileIterator, using TileShape, Element, Layout, and ThreadMap typesusing Iterator = cutlass::transform::threadblock::PredicatedTileIterator&lt; Shape, Element, Layout, 1, ThreadMap&gt;;cutlass::Coord&lt;2&gt; copy_extent = cutlass::make_Coord(M, K);cutlass::Coord&lt;2&gt; alloc_extent = cutlass::make_Coord(M, K);// another way to define tensor// Allocate source and destination tensorscutlass::HostTensor&lt;Element, Layout&gt; src_tensor(alloc_extent);cutlass::HostTensor&lt;Element, Layout&gt; dst_tensor(alloc_extent);Element oob_value = Element(-1);// Initialize destination tensor with all -1scutlass::reference::host::TensorFill(dst_tensor.host_view(), oob_value);// Initialize source tensor with sequentially increasing valuescutlass::reference::host::BlockFillSequential(src_tensor.host_data(), src_tensor.capacity());dst_tensor.sync_device();src_tensor.sync_device();typename Iterator::Params dst_params(dst_tensor.layout());typename Iterator::Params src_params(src_tensor.layout());dim3 block(kThreads, 1);dim3 grid(1, 1);// Launch copy kernel to perform the copycopy&lt;Iterator&gt;&lt;&lt;&lt; grid, block &gt;&gt;&gt;( dst_params, dst_tensor.device_data(), src_params, src_tensor.device_data(), copy_extent);// copy functiontemplate &lt;typename Iterator&gt;__global__ void copy( typename Iterator::Params dst_params, typename Iterator::Element *dst_pointer, typename Iterator::Params src_params, typename Iterator::Element *src_pointer, cutlass::Coord&lt;2&gt; extent) { Iterator dst_iterator(dst_params, dst_pointer, extent, threadIdx.x); Iterator src_iterator(src_params, src_pointer, extent, threadIdx.x); // PredicatedTileIterator uses PitchLinear layout and therefore takes in a PitchLinearShape. // The contiguous dimension can be accessed via Iterator::Shape::kContiguous and the strided // dimension can be accessed via Iterator::Shape::kStrided int iterations = (extent[1] + Iterator::Shape::kStrided - 1) / Iterator::Shape::kStrided; typename Iterator::Fragment fragment; for(; iterations &gt; 0; --iterations) { src_iterator.load(fragment); dst_iterator.store(fragment); ++src_iterator; ++dst_iterator; }}","link":"/2023/03/20/learn-cutlass-0/"},{"title":"learn-cutlass-1","text":"In cutlass 3.0, it introduces a new library, Cute, to describe and manipulate tensors of threads and data. I think the core of cutlass is GEMM(or other computations) and data movement. Different types of GEMM TYPE of GEMM BITS of DATA TYPE of DATA HGEMM 16 floating-point number SGEMM 32 floating-point number DGEMM 64 floating-point number IGEMM 8 or 16 or 32 or 64 integer RowMajorInterleaved (ColumnMajorInterleaved)12#include &quot;cutlass/layout/matrix.h&quot;template&lt;int Interleave&gt; struct cutlass::layout::RowMajorInterleaved&lt;Interleave&gt;; RowMajorInterleaved is a layout which confused me. I didn’t know the meaning of Interleaved.So I create an example to figure it out. 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;cstdio&gt;// Defines cutlass::layout::RowMajorInterleave#include &quot;cutlass/layout/matrix.h&quot;// Defines cutlass::HostTensor&lt;&gt;#include &quot;cutlass/util/host_tensor.h&quot;// Defines cutlass::MatrixCoord#include &quot;cutlass/matrix_coord.h&quot;#define M 4#define N 4int main(){ cutlass::HostTensor&lt;int,cutlass::layout::RowMajorInterleaved&lt;2&gt; &gt; A(cutlass::MatrixCoord(M,N)); int num = 0; for(int i=0;i&lt;M;i++) for(int j=0;j&lt;N;j++){ A.at({i,j}) = ++num; } int *A_ = A.host_data(); for(int i=0;i&lt;A.capacity();i++){ printf(&quot;%3d &quot;,A_[i]); // if((i+1)%N==0)printf(&quot;\\n&quot;); } /** * output: * 1 5 2 6 3 7 4 8 9 13 10 14 11 15 12 16 * */} If tensor A is a simple RowMajor, the output should be this 11 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 In my opinion, Interleaved means it will iterate in shape(1) with size Interleave and then iterate in shape(0).Other things need to mind is Interleaved may cause padding of a matrix, like 1234567891011#define M 3#define N 3cutlass::HostTensor&lt;int,cutlass::layout::RowMajorInterleaved&lt;2&gt; &gt; A(cutlass::MatrixCoord(M,N));int num = 0;for(int i=0;i&lt;M;i++)for(int j=0;j&lt;N;j++){ A.at({i,j}) = ++num; }/** * the element in A should be * 1 4 2 5 3 6 7 0 8 0 9 0 typename in C++In cutlass, you will see typename everywhere. Obviously, you can use typename when building template. But it has other usage, such as The following is generated by chatgpt 12345template&lt;typename T&gt;void foo() { typename T::iterator it; // ...} In C++, the typename keyword is used to specify that a dependent name is a type. A dependent name is a name that depends on a template parameter, and the compiler cannot determine whether the name refers to a type or some other entity until the template is instantiated with concrete types. Consider the above example. Here, T::iterator is a dependent name because it depends on the template parameter T. Without the typename keyword, the compiler would not be able to determine whether T::iterator is a type or a member variable until T is instantiated with a concrete type. The typename keyword tells the compiler that T::iterator is a type. Note that typename is only needed when using a dependent name as a type. If the name does not depend on a template parameter, or if it is not used as a type, the typename keyword should not be used. ThreadblockSwizzle The following is generated by chatgpt In Cutlass, ThreadblockSwizzle is a feature that allows for different threadblock configurations to be used when performing matrix-multiplication operations. ThreadblockSwizzle can be used to optimize the performance of GEMM (General Matrix Multiply) operations on GPUs, by mapping the threadblocks to the data in a way that maximizes data reuse and minimizes thread divergence. ThreadblockSwizzle functions in Cutlass can be used to map the blockIdx (block index) of the CUDA grid to GEMM problems. These functions implement different strategies for organizing the threads within a threadblock, such as tiling, padding, and transposing, in order to improve the efficiency of memory access patterns and to maximize the utilization of GPU resources. Overall, ThreadblockSwizzle in Cutlass is a powerful feature that can significantly improve the performance of matrix-multiplication operations on GPUs, particularly for large-scale problems. Comparison between typedef and using The following is generated by chatgpt In C++, both typedef and using can be used to create aliases for types. Here are some key differences between the two: Syntax12typedef &lt;existing_type&gt; &lt;new_type_alias&gt;;using &lt;new_type_alias&gt; = &lt;existing_type&gt;; Scopetypedef: A type alias created using typedef has the same scope as the original type. This means that it is accessible anywhere that the original type is accessible. using: A type alias created using using has a narrower scope than the original type. It is only accessible within the block in which it is defined. Functionalitytypedef: typedef can only be used to create aliases for types. It cannot be used to create template aliases. using: using can be used to create both type aliases and template aliases. This makes it more versatile than typedef. Readabilitytypedef: typedef can only be used to create aliases for types. It cannot be used to create template aliases. using: using can be used to create both type aliases and template aliases. This makes it more versatile than typedef. 05_batched_gemmBatched gemm can be illustrated as follows In the example, it simply calls two APIs which is cutlass::gemm::device::GemmArray and cutlass::gemm::device::GemmBatched. So I think it is time to read the source of cutlass. GemmArrayLet’s take GemmArray as an example. 1234567891011121314151617181920212223242526272829// GemmArray is defined in following file#include &quot;cutlass/gemm/device/gemm_array.h&quot;// simplified defination of GemmArraytemlate&lt; typename ElementA_, typename LayoutA_, typename ElementB_, typename LayoutB_, typename ElementC_, typename LayoutC_ //...&gt;class GemmArray{ public: // ignore some detailed attribute and functions using GemmKernel = kernel::GemmArray&lt;typename DefaultGemmKernel::Mma, typename DefaultGemmKernel::Epilogue, ThreadblockSwizzle&gt;; Status run(cudaStream_t stream = nullptr) { // ignore some detailed codes cutlass::Kernel&lt;GemmKernel&gt;&lt;&lt;&lt;grid, block, smem_size, stream&gt;&gt;&gt;(params_); } // overload operator () for calling gemm_op(...) Status operator()(cudaStream_t stream = nullptr) { return run(stream); }}; See, it is not very complicated. The class GemmArray is just built with many templates(the context of a class) and overloads operator () to call cutlass::Kernel. Then the question is coming. What is cutlass:Kernal? 1234567891011121314151617#include &quot;cutlass/device_kernel.h&quot;/// Generic CUTLASS kernel template.template &lt;typename Operator&gt;__global__void Kernel(typename Operator::Params params) { // Dynamic shared memory base pointer extern __shared__ int SharedStorageBase[]; // Declare pointer to dynamic shared memory. typename Operator::SharedStorage *shared_storage = reinterpret_cast&lt;typename Operator::SharedStorage *&gt;(SharedStorageBase); Operator op; op(params, *shared_storage);}; It is just a kernel template. So the important is Opearator of cutlass::Kernal which stands for cutlass::gemm::kernel::GemmArray. 123456789101112131415#include &quot;cutlass/gemm/kernel/gemm_array.h&quot;template &lt; typename Mma_, ///! Threadblock-scoped matrix multiply-accumulate typename Epilogue_, ///! Epilogue typename ThreadblockSwizzle_ ///! Threadblock swizzling function&gt;struct GemmArray{ // ignore some detailed attribute and functions CUTLASS_DEVICE void operator()(Params const &amp;params, SharedStorage &amp;shared_storage) { // codes run on device }}; So operator() is the core of class/struct in cutlass. And all the others are the context of that class/struct.","link":"/2023/03/21/learn-cutlass-1/"}],"tags":[{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Icarus","slug":"Icarus","link":"/tags/Icarus/"},{"name":"cutlass","slug":"cutlass","link":"/tags/cutlass/"}],"categories":[{"name":"Technology","slug":"Technology","link":"/categories/Technology/"}],"pages":[{"title":"Tianyu Guo (郭天宇)","text":"E-mail : guoty9[at]mail2.sysu.edu.cn My Resume Education Experience year university degree 2018 - 2022 Xidian University B.S. 2022 - now Sun Yat-Sen University Master Experience Teaching Assistant of “SYSU-DCS3013 : Computer Architecture” [2022f] release SYSU-ARCH LAB Research Bachelor’s dissertation “General Computing optimization for GPU based on Cache management” AI final Homework “A Convolutional Neural Network Framework support on CPU and GPU”","link":"/info/index.html"}]}